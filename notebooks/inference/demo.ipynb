{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference on GRPO Checkpoint\n",
    "\n",
    "Load a trained GRPO checkpoint and run inference on math problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version: 0.8.1\n",
      "Devices: [CudaDevice(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 20:46:45.915603  165749 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1202 20:46:45.918463  165572 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "\n",
    "from tunix_hack.models import load_model, load_tokenizer, list_checkpoints, find_checkpoint, restore_checkpoint\n",
    "from tunix_hack.inference import create_sampler, generate\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: google/gemma-3-1b-it\n",
      "USE_LORA: True\n",
      "Checkpoint: demo/step 45\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "PROJECT_ROOT = Path(\"/home/jimnix/gitrepos/tunix-hack\")\n",
    "CKPT_ROOT = PROJECT_ROOT / \"outputs\" / \"checkpoints\" / \"grpo\"\n",
    "\n",
    "# Model\n",
    "MODEL_ID = \"google/gemma-3-1b-it\"\n",
    "MESH = ((1, 1), (\"fsdp\", \"tp\"))\n",
    "\n",
    "# LoRA config (set USE_LORA=False for pure base model)\n",
    "USE_LORA = True\n",
    "LORA_RANK = 16\n",
    "LORA_ALPHA = 16\n",
    "\n",
    "# Checkpoint selection (only used if USE_LORA=True)\n",
    "RUN_NAME = \"demo\"\n",
    "CHECKPOINT_STEP = 45\n",
    "\n",
    "# Generation config\n",
    "MAX_TOKENS = 256\n",
    "\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"USE_LORA: {USE_LORA}\")\n",
    "if USE_LORA:\n",
    "    print(f\"Checkpoint: {RUN_NAME}/step {CHECKPOINT_STEP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Interactive Checkpoint Picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available checkpoints:\n",
      "----------------------------------------\n",
      "  demo / step 30\n",
      "  demo / step 40\n",
      "  demo / step 45 <--\n",
      "----------------------------------------\n",
      "\n",
      "Will load: /home/jimnix/gitrepos/tunix-hack/outputs/checkpoints/grpo/demo/actor/45/model_params\n"
     ]
    }
   ],
   "source": [
    "# List available checkpoints\n",
    "if USE_LORA:\n",
    "    checkpoints = list_checkpoints(CKPT_ROOT)\n",
    "    \n",
    "    if not checkpoints:\n",
    "        raise ValueError(f\"No checkpoints found in {CKPT_ROOT}\")\n",
    "    \n",
    "    print(\"Available checkpoints:\")\n",
    "    print(\"-\" * 40)\n",
    "    for ckpt in checkpoints:\n",
    "        marker = \" <--\" if ckpt[\"run\"] == RUN_NAME and ckpt[\"step\"] == str(CHECKPOINT_STEP) else \"\"\n",
    "        print(f\"  {ckpt['run']} / step {ckpt['step']}{marker}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find the selected checkpoint\n",
    "    ckpt_path = find_checkpoint(CKPT_ROOT, RUN_NAME, CHECKPOINT_STEP)\n",
    "    if ckpt_path is None:\n",
    "        raise ValueError(f\"Checkpoint not found: {RUN_NAME}/step {CHECKPOINT_STEP}\")\n",
    "    print(f\"\\nWill load: {ckpt_path}\")\n",
    "else:\n",
    "    ckpt_path = None\n",
    "    print(\"USE_LORA=False: Using pure base model (no checkpoint)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh: Mesh('fsdp': 1, 'tp': 1, axis_types=(Auto, Auto))\n",
      "\n",
      "Loading google/gemma-3-1b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165572/4044193080.py:2: DeprecationWarning: The default axis_types will change in JAX v0.9.0 to jax.sharding.AxisType.Explicit. To maintain the old behavior, pass `axis_types=(jax.sharding.AxisType.Auto,) * len(axis_names)`. To opt-into the new behavior, pass `axis_types=(jax.sharding.AxisType.Explicit,) * len(axis_names)\n",
      "  mesh = jax.make_mesh(*MESH)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af46d943df7349a6b7a34a7db41f57ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Create mesh and load model\n",
    "mesh = jax.make_mesh(*MESH)\n",
    "print(f\"Mesh: {mesh}\")\n",
    "\n",
    "print(f\"\\nLoading {MODEL_ID}...\")\n",
    "model, model_config, model_path = load_model(\n",
    "    MODEL_ID,\n",
    "    mesh,\n",
    "    use_lora=USE_LORA,\n",
    "    lora_rank=LORA_RANK,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    ")\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = load_tokenizer(model_path)\n",
    "print(\"Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring checkpoint from: /home/jimnix/gitrepos/tunix-hack/outputs/checkpoints/grpo/demo/actor/45/model_params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimnix/gitrepos/tunix-hack/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/jax_array_handlers.py:711: UserWarning: Sharding info not provided when restoring. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored!\n"
     ]
    }
   ],
   "source": [
    "# Restore checkpoint (if using LoRA)\n",
    "if USE_LORA and ckpt_path:\n",
    "    print(f\"Restoring checkpoint from: {ckpt_path}\")\n",
    "    restore_checkpoint(model, ckpt_path)\n",
    "    print(\"Checkpoint restored!\")\n",
    "else:\n",
    "    print(\"Using base model weights (no checkpoint to restore)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sampler...\n",
      "Sampler ready!\n"
     ]
    }
   ],
   "source": [
    "# Create sampler\n",
    "print(\"Creating sampler...\")\n",
    "sampler = create_sampler(model, tokenizer, model_config)\n",
    "print(\"Sampler ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to generate! Use ask('your question') or generate(sampler, mesh, question)\n"
     ]
    }
   ],
   "source": [
    "# Test generation\n",
    "def ask(question: str, **kwargs) -> str:\n",
    "    \"\"\"Convenience wrapper for generate().\"\"\"\n",
    "    return generate(sampler, mesh, question, max_tokens=MAX_TOKENS, system_prompt='', **kwargs)\n",
    "\n",
    "print(\"Ready to generate! Use ask('your question') or generate(sampler, mesh, question)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 + 2 = 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(ask(\"What is 2 + 2?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "============================================================\n",
      "\n",
      "Q: What is 15 + 27?\n",
      "----------------------------------------\n",
      "\n",
      "15 + 27 = 42\n",
      "\n",
      "So the answer is 42.\n",
      "============================================================\n",
      "\n",
      "Q: If Mary has 5 apples and gives 2 to John, how many apples does Mary have?\n",
      "----------------------------------------\n",
      "Mary has 3 apples.\n",
      "\n",
      "Here's the solution:\n",
      "\n",
      "* Start with: 5 apples\n",
      "* Subtract: 2 apples\n",
      "* Result: 5 - 2 = 3 apples\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Q: A store sells 3 books for $12. How much does one book cost?\n",
      "----------------------------------------\n",
      "Let the cost of one book be $x$.\n",
      "The store sells 3 books for $12.\n",
      "So, the total cost of 3 books is $12.\n",
      "We can write the equation:\n",
      "3x = 12\n",
      "To find the cost of one book, we divide both sides of the equation by 3:\n",
      "x = \\frac{12}{3}\n",
      "x = 4\n",
      "Therefore, one book costs $4.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{4}$\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test on a few examples\n",
    "test_questions = [\n",
    "    \"What is 15 + 27?\",\n",
    "    \"If Mary has 5 apples and gives 2 to John, how many apples does Mary have?\",\n",
    "    \"A store sells 3 books for $12. How much does one book cost?\",\n",
    "]\n",
    "\n",
    "print(\"Testing model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(ask(q))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Interactive Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Interactive mode - enter math questions (type 'quit' to exit)\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# while True:\n",
    "#     question = input(\"\\nYour question: \").strip()\n",
    "    \n",
    "#     if question.lower() in ('quit', 'exit', 'q'):\n",
    "#         print(\"Goodbye!\")\n",
    "#         break\n",
    "    \n",
    "#     if not question:\n",
    "#         continue\n",
    "    \n",
    "#     print(\"-\" * 40)\n",
    "#     print(ask(question))\n",
    "#     print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tunix-hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
